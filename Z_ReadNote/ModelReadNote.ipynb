{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Backbone",
   "id": "11cb2f0103110e46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DownTransition(nn.Module):\n",
    "    def __init__(self, in_ch, depth, act):\n",
    "        super(DownTransition, self).__init__()\n",
    "    pass\n",
    "\n",
    "class UpTransition(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, depth, act):\n",
    "        super(UpTransition, self).__init__()\n",
    "    pass\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, act='relu'):\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "        self.down_tr64 = DownTransition(1,0,act)\n",
    "        self.down_tr128 = DownTransition(64,1,act)\n",
    "        self.down_tr256 = DownTransition(128,2,act)\n",
    "        self.down_tr512 = DownTransition(256,3,act)\n",
    "\n",
    "        self.up_tr256 = UpTransition(512, 512,2,act)\n",
    "        self.up_tr128 = UpTransition(256,256, 1,act)\n",
    "        self.up_tr64 = UpTransition(128,128,0,act)\n",
    "        # self.out_tr = OutputTransition(64, n_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.out64, self.skip_out64 = self.down_tr64(x)\n",
    "        self.out128,self.skip_out128 = self.down_tr128(self.out64)\n",
    "        self.out256,self.skip_out256 = self.down_tr256(self.out128)\n",
    "        self.out512,self.skip_out512 = self.down_tr512(self.out256)  # 降采样后得到的高层次特征表示\n",
    "\n",
    "        self.out_up_256 = self.up_tr256(self.out512,self.skip_out256)\n",
    "        self.out_up_128 = self.up_tr128(self.out_up_256, self.skip_out128)\n",
    "        self.out_up_64 = self.up_tr64(self.out_up_128, self.skip_out64)  # 上采样后供分类的低层次特征表示\n",
    "        # self.out = self.out_tr(self.out_up_64)\n",
    "\n",
    "        return self.out512, self.out_up_64"
   ],
   "id": "5e6a705dd66846dc"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UM, self).__init__()\n",
    "        self.backbone = UNet3D()  # 选择骨干网络\n",
    "        pass\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        dec4, x = self.backbone(x_in)  # 骨干网络返回两个结果"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在 `Universal_model` 类中，`UNet3D` 网络通常会返回两个主要的输出，分别是 `out512` 和 `out_up_64`。这两个输出代表不同阶段的特征图，具体如下：\n",
    "\n",
    "### 1. `out512`\n",
    "- **描述**: `out512` 是从 `UNet3D` 的最后一层（通常是编码器的最后一层）得到的特征图，具有 512 个通道。\n",
    "- **用途**: \n",
    "  - 这个输出包含了对输入数据的高层次、抽象的特征表示，通常用于进行进一步的分类或回归任务。\n",
    "  - 在医学图像分割任务中，`out512` 会被用作后续处理的输入，可能会经过一些额外的卷积层或全局平均池化层，以提取更具语义的信息。\n",
    "\n",
    "### 2. `out_up_64`\n",
    "- **描述**: `out_up_64` 是从 `UNet3D` 的上采样阶段得到的特征图，通常具有 64 个通道。\n",
    "- **用途**: \n",
    "  - 这个输出通常是经过解码器的上采样过程后得到的，包含了较低层次的细节信息。\n",
    "  - 在分割任务中，`out_up_64` 可能用于与其他特征图（如 `out512`）进行拼接，帮助恢复图像细节，从而提高分割精度。\n",
    "\n",
    "### 总结\n",
    "- **`out512`**: 高层次的特征表示，通常用于分类或作为进一步处理的基础。\n",
    "- **`out_up_64`**: 经过上采样的特征，包含细节信息，常用于精细化分割任务。\n",
    "\n",
    "这两个输出结合使用，使得模型在处理医学图像时，既能捕获全局语义信息，又能保留局部细节，从而提高整体性能。"
   ],
   "id": "a163776dd4525f57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UM forward",
   "id": "a2f151538999b810"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:11:08.145720Z",
     "start_time": "2024-10-06T12:11:06.002423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UM(nn.Module):\n",
    "    def __init__(self,img_size, in_ch, out_ch, backbone = 'Unet3', encoding = 'rand_embedding'):\n",
    "        super(UM, self).__init__()\n",
    "        \n",
    "        # 获取骨干网络参数\n",
    "        self.backbone_name = backbone\n",
    "        if backbone == 'Unet':\n",
    "            self.backbone = UNet3D()\n",
    "            \n",
    "            # 预处理层(骨干网络最终输出out,输入进分割头前)\n",
    "            self.precls_conv = nn.Sequential(\n",
    "                nn.GroupNorm(16, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv3d(64,8, kernel_size=1, stride=1, padding=0),\n",
    "            )\n",
    "            \n",
    "            # 全局平均池化GAP(应用于高层次特征)\n",
    "            self.GAP = nn.Sequential(\n",
    "                nn.GroupNorm(16,512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                torch.nn.AdaptiveAvgPool3d((1,1,1)),\n",
    "                nn.Conv3d(in_channels=1, out_channels=256, kernel_size=1, stride=1, padding=0),\n",
    "            )\n",
    "        \n",
    "        pass\n",
    "        \n",
    "        # 获取权重和偏置数\n",
    "        weight_nums, bias_nums = [], []\n",
    "        pass\n",
    "        self.weight_nums = weight_nums\n",
    "        self.bias_nums = bias_nums\n",
    "        \n",
    "        # 控制器(用于生成动态模型参数)\n",
    "        self.controller = nn.Conv3d(256+256, sum(weight_nums+bias_nums), kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        # 获取编码方式参数\n",
    "        self.encoding = encoding\n",
    "        if self.encoding == 'rand_embedding':\n",
    "            self.organ_embedding = nn.Embedding(out_ch, 256)\n",
    "        elif self.encoding == 'word_embedding':\n",
    "            self.register_buffer('organ_embedding', torch.randn(out_ch, 512))\n",
    "            self.text_to_vision = nn.Linear(512, 256)\n",
    "        \n",
    "        # 设置分类数\n",
    "        self.class_num = out_ch\n",
    "    \n",
    "    def load_params(self):\n",
    "        pass\n",
    "    \n",
    "    def encoding_task(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    def parse_dynamic_params(self, params, channels, weight_nums, bias_nums):\n",
    "        pass\n",
    "        return _, _\n",
    "    \n",
    "    def heads_forward(self, features, weights, biases, num_insts):\n",
    "        return _\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        # 获取backbone的两个输出\n",
    "        dec4, out = self.backbone(x_in)  # 返回:降采样后高层次特征dec4,上采样后低层次特征out\n",
    "        \n",
    "        # 选择嵌入方式\n",
    "        if self.encoding == 'rand_embedding':\n",
    "            task_encoding = self.organ_embedding.weight.unsqueeze(2).unsqueeze(2).unsqueeze(2)\n",
    "        elif self.encoding == 'word_embedding':\n",
    "            task_encoding = F.relu(self.text_to_vision(self.organ_embedding))\n",
    "            task_encoding = task_encoding.unsqueeze(2).unsqueeze(2).unsqueeze(2)\n",
    "        # task_encoding torch.Size([31,256,1,1,1])\n",
    "        \n",
    "        # 全局平均池化GAP\n",
    "        x_feat = self.GAP(dec4)   # torch.Size([batch_size,channels,1,1,1])\n",
    "        b = x_feat.shape[0]  # 批次大小\n",
    "        \n",
    "        # 循环处理每个实例\n",
    "        \n",
    "        # 初始化logits数组,用于存储每个实例的输出logits\n",
    "        logits_array = []\n",
    "        \n",
    "        # 遍历每个实例\n",
    "        for i in range(b):\n",
    "            # 将当前实例的特征x_feat[i](经过unsqueeze增加维度后)和任务编码拼接,形成条件输出\n",
    "            x_cond = torch.cat([x_feat[i].unsqueeze(0).repeat(self.class_num,1,1,1,1), task_encoding], 1)\n",
    "            \n",
    "            # 生成动态参数\n",
    "            params = self.controller(x_cond)  # 通过控制器生成动态参数\n",
    "            params.squeeze_(-1).squeeze_(-1).squeeze_(-1)  # 删除后三维,降低维度\n",
    "            \n",
    "            # 预处理骨干网络输出out,供分割头使用\n",
    "            head_inputs = self.precls_conv(out[i].unsqueeze(0))\n",
    "            head_inputs = head_inputs.repeat(self.class_num,1,1,1,1)  # 重复class_num次,得到适用于每个类的输出\n",
    "            \n",
    "            # 获取尺寸,重塑以进行卷积\n",
    "            N, _, D, H, W = head_inputs.size()\n",
    "            head_inputs = head_inputs.reshape(1,-1,D,H,W)\n",
    "            # print(head_inputs.shape, params.shape)\n",
    "            \n",
    "            # 解析动态参数\n",
    "            weights, biases = self.parse_dynamic_params(params, 0, self.weight_nums, self.bias_nums)\n",
    "            \n",
    "            # 执行头部前向计算\n",
    "            logits = self.heads_forward(head_inputs, weights, biases, N)  # 得到当前实例的输出\n",
    "            \n",
    "            # 存储输出\n",
    "            logits_array.append(logits.reshape(1,-1,D,H,W))\n",
    "            \n",
    "        # 合并输出\n",
    "        out = torch.cat(logits_array, dim=0)\n",
    "        \n",
    "        return out   "
   ],
   "id": "6b2ec1f2b3e5ab68",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# todo\n",
    "1. 选择编码方式\n",
    "    1. nn.Embedding\n",
    "    2. register_buffer \n",
    "2. logits数组\n",
    "3. 权重和偏置数\n",
    "4. 生成动态参数\n",
    "5. 参数控制器controller\n",
    "6. heads_forward"
   ],
   "id": "f99912724c709adb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "283fb419f5f27329"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
